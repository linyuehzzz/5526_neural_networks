{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linyuehzzz/5526_neural_networks/blob/master/ConvNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBFQZ--ju_nQ"
      },
      "source": [
        "This code provides some examples of how to train a deep neural network for the Fashion-MNIST database.  You can use this as a training/test harness for developing your own ConvNet.\n",
        "\n",
        "Note that you will probably want to change your runtime to use GPU rather than CPU for this task, if you are on Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVcdbKGfu7Mt"
      },
      "source": [
        "# import standard PyTorch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
        "\n",
        "\n",
        "# import torchvision module to handle image manipulation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_ra6PVjwCoa"
      },
      "source": [
        "The following library call downloads the training set and puts it into data/FashionMNIST, and prepares the dataset to be passed into a pytorch as a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtphcZeJvs8x"
      },
      "source": [
        "# Use standard FashionMNIST dataset\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")\n",
        "\n",
        "test_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = False,\n",
        "    download = False,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYmzeeyHxDCs"
      },
      "source": [
        "Here I'm defining a network that is a 2-layer DNN.  You will want to replace this with the ConvNet definitions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVhVxfNFwRLd"
      },
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # define layers\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 12, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(6*6*12, 256),\n",
        "            nn.ReLU())\n",
        "        self.fc = nn.Linear(in_features=256,out_features=10)\n",
        "\n",
        "        # self.fc1 = nn.Linear(in_features=28*28,out_features=200)\n",
        "        # self.fc2 = nn.Linear(in_features=200,out_features=10)\n",
        "\n",
        "\n",
        "    # define forward function\n",
        "    def forward(self, t):\n",
        "        t = self.layer1(t)\n",
        "        t = self.layer2(t)\n",
        "        t = t.reshape(t.size(0), -1)\n",
        "        t = self.layer3(t)\n",
        "        t = self.fc(t)\n",
        "        \n",
        "        # # fc 1\n",
        "        # t = t.reshape(-1, 28*28)\n",
        "        # t = self.fc1(t)\n",
        "        # t = F.relu(t)\n",
        "\n",
        "        # # fc 2\n",
        "        # t = self.fc2(t)\n",
        "        # # don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "        return t"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzhKnPcSd3RP"
      },
      "source": [
        "Auxiliary function that reports the accuracy on a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuKEqezweA_S"
      },
      "source": [
        "def get_accuracy(model,dataloader):\n",
        "    count=0\n",
        "    correct=0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            images = batch[0]\n",
        "            labels = batch[1]\n",
        "            preds = network(images)\n",
        "            batch_correct = preds.argmax(dim=1).eq(labels).sum().item()\n",
        "            batch_count = len(batch[0])\n",
        "            count += batch_count\n",
        "            correct += batch_correct\n",
        "    model.train()\n",
        "    return correct/count"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIkypu3WdfiV"
      },
      "source": [
        "Train the model for three epochs (by default); report the training set accuracy after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq2sgd0sH5mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6033c2-8f3a-4449-f841-cc002bfca85a"
      },
      "source": [
        "lr=0.001\n",
        "batch_size=1000\n",
        "shuffle=True\n",
        "epochs=10\n",
        "\n",
        "network = Network()\n",
        "loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
        "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
        "\n",
        "# set the network to training mode\n",
        "network.train()\n",
        "for epoch in range(epochs):\n",
        "    for batch in loader:\n",
        "        images = batch[0]\n",
        "        labels = batch[1]\n",
        "        preds = network(images)\n",
        "        loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Epoch {0}: train set accuracy {1}'.format(epoch,get_accuracy(network,loader)))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
        "print('Epoch {0}: test set accuracy {1}'.format(epoch,get_accuracy(network,test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train set accuracy 0.7553666666666666\n",
            "Epoch 1: train set accuracy 0.7988833333333333\n",
            "Epoch 2: train set accuracy 0.8226666666666667\n",
            "Epoch 3: train set accuracy 0.8388333333333333\n",
            "Epoch 4: train set accuracy 0.8514666666666667\n",
            "Epoch 5: train set accuracy 0.8599\n",
            "Epoch 6: train set accuracy 0.8665666666666667\n",
            "Epoch 7: train set accuracy 0.8724666666666666\n",
            "Epoch 8: train set accuracy 0.8759333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}